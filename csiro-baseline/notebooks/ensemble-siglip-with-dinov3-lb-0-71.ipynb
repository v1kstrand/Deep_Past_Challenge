{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aebf53aa",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2026-01-15T06:28:59.598394Z",
     "iopub.status.busy": "2026-01-15T06:28:59.598157Z",
     "iopub.status.idle": "2026-01-15T06:46:04.438211Z",
     "shell.execute_reply": "2026-01-15T06:46:04.437304Z"
    },
    "papermill": {
     "duration": 1024.845621,
     "end_time": "2026-01-15T06:46:04.439849",
     "exception": false,
     "start_time": "2026-01-15T06:28:59.594228",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/sqlalchemy/orm/query.py:195: SyntaxWarning: \"is not\" with 'tuple' literal. Did you mean \"!=\"?\n",
      "  if entities is not ():\n",
      "2026-01-15 06:29:22.281828: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1768458562.466829      31 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1768458562.523006      31 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1768458562.962990      31 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1768458562.963026      31 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1768458562.963029      31 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1768458562.963031      31 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Data...\n",
      "Computing Embeddings for 357 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b1b7162c07c412693d9292e1d086060",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/357 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing Embeddings for 1 images...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e6205d66ca64fecaa9d806d8abc2f90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Features Shape: (357, 1165)\n",
      "Test Features Shape: (1, 1158)\n",
      "Generating Semantic Features...\n",
      "Training & Inferring Models...\n",
      "Model: HistGradientBoosting\n",
      "Processing Fold 0...\n",
      "Processing Fold 1...\n",
      "Processing Fold 2...\n",
      "Processing Fold 3...\n",
      "Processing Fold 4...\n",
      "Model: GradientBoosting\n",
      "Processing Fold 0...\n",
      "Processing Fold 1...\n",
      "Processing Fold 2...\n",
      "Processing Fold 3...\n",
      "Processing Fold 4...\n",
      "Model: CatBoost\n",
      "Processing Fold 0...\n",
      "Processing Fold 1...\n",
      "Processing Fold 2...\n",
      "Processing Fold 3...\n",
      "Processing Fold 4...\n",
      "Model: LightGBM\n",
      "Processing Fold 0...\n",
      "Processing Fold 1...\n",
      "Processing Fold 2...\n",
      "Processing Fold 3...\n",
      "Processing Fold 4...\n",
      "Ensembling and Post-processing...\n",
      "✓ Siglip submission generated: submission_siglip.csv\n",
      "                    sample_id     target\n",
      "0  ID1001187975__Dry_Clover_g   3.730718\n",
      "1    ID1001187975__Dry_Dead_g  21.481835\n",
      "2   ID1001187975__Dry_Green_g  28.551182\n",
      "3   ID1001187975__Dry_Total_g  53.763735\n",
      "4         ID1001187975__GDM_g  32.281900\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import gc\n",
    "import random\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import torch\n",
    "from PIL import Image\n",
    "from tqdm.auto import tqdm\n",
    "from pathlib import Path\n",
    "from copy import deepcopy\n",
    "from dataclasses import dataclass\n",
    "\n",
    "# Sklearn & Models\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.ensemble import GradientBoostingRegressor, HistGradientBoostingRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "from transformers import AutoModel, AutoImageProcessor, AutoTokenizer\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "# =========================================================================================\n",
    "# 1. CONFIGURATION & SEEDING\n",
    "# =========================================================================================\n",
    "@dataclass\n",
    "class Config:\n",
    "    DATA_PATH: Path = Path(\"/kaggle/input/csiro-biomass/\")\n",
    "    SPLIT_PATH: Path = Path(\"/kaggle/input/csiro-datasplit/csiro_data_split.csv\")\n",
    "    SIGLIP_PATH: str = \"/kaggle/input/google-siglip-so400m-patch14-384/transformers/default/1\"\n",
    "    \n",
    "    SEED: int = 42\n",
    "    DEVICE: str = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    PATCH_SIZE: int = 520\n",
    "    OVERLAP: int = 16\n",
    "    \n",
    "    # Target definitions\n",
    "    TARGET_NAMES = ['Dry_Clover_g', 'Dry_Dead_g', 'Dry_Green_g', 'Dry_Total_g', 'GDM_g']\n",
    "    TARGET_MAX = {\n",
    "        \"Dry_Clover_g\": 71.7865,\n",
    "        \"Dry_Dead_g\": 83.8407,\n",
    "        \"Dry_Green_g\": 157.9836,\n",
    "        \"Dry_Total_g\": 185.70,\n",
    "        \"GDM_g\": 157.9836,\n",
    "    }\n",
    "\n",
    "cfg = Config()\n",
    "\n",
    "def seeding(SEED):\n",
    "    np.random.seed(SEED)\n",
    "    random.seed(SEED)\n",
    "    os.environ['PYTHONHASHSEED'] = str(SEED)\n",
    "    torch.manual_seed(SEED)\n",
    "    if torch.cuda.is_available(): \n",
    "        torch.cuda.manual_seed(SEED)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "\n",
    "seeding(cfg.SEED)\n",
    "\n",
    "# =========================================================================================\n",
    "# 2. DATA LOADING & PRE-PROCESSING\n",
    "# =========================================================================================\n",
    "def pivot_table(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    if 'target' in df.columns.tolist():\n",
    "        # Train data\n",
    "        df_pt = pd.pivot_table(\n",
    "            df, \n",
    "            values='target', \n",
    "            index=['image_path', 'Sampling_Date', 'State', 'Species', 'Pre_GSHH_NDVI', 'Height_Ave_cm'], \n",
    "            columns='target_name', \n",
    "            aggfunc='mean'\n",
    "        ).reset_index()\n",
    "    else:\n",
    "        # Test data\n",
    "        df['target'] = 0\n",
    "        df_pt = pd.pivot_table(\n",
    "            df, \n",
    "            values='target', \n",
    "            index='image_path', \n",
    "            columns='target_name', \n",
    "            aggfunc='mean'\n",
    "        ).reset_index()\n",
    "    return df_pt\n",
    "\n",
    "def melt_table(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    melted = df.melt(\n",
    "        id_vars='image_path',\n",
    "        value_vars=cfg.TARGET_NAMES,\n",
    "        var_name='target_name',\n",
    "        value_name='target'\n",
    "    )\n",
    "    # Create sample_id matching submission format\n",
    "    melted['sample_id'] = (\n",
    "        melted['image_path']\n",
    "        .str.replace(r'^.*/', '', regex=True)\n",
    "        .str.replace('.jpg', '', regex=False)\n",
    "        + '__' + melted['target_name']\n",
    "    )\n",
    "    return melted[['sample_id', 'target']]\n",
    "\n",
    "def post_process_biomass(df_preds):\n",
    "    \"\"\"Enforce mass balance: Green+Clover=GDM, GDM+Dead=Total using projection.\"\"\"\n",
    "    ordered_cols = [\"Dry_Green_g\", \"Dry_Clover_g\", \"Dry_Dead_g\", \"GDM_g\", \"Dry_Total_g\"]\n",
    "    \n",
    "    # Ensure cols exist\n",
    "    for c in ordered_cols:\n",
    "        if c not in df_preds.columns:\n",
    "            df_preds[c] = 0.0\n",
    "\n",
    "    Y = df_preds[ordered_cols].values.T\n",
    "    \n",
    "    # Constraint Matrix: Cx = 0\n",
    "    C = np.array([\n",
    "        [1, 1, 0, -1,  0],\n",
    "        [0, 0, 1,  1, -1]\n",
    "    ])\n",
    "    \n",
    "    # Projection Matrix P = I - C^T(CC^T)^-1 C\n",
    "    C_T = C.T\n",
    "    try:\n",
    "        inv_CCt = np.linalg.inv(C @ C_T)\n",
    "        P = np.eye(5) - C_T @ inv_CCt @ C\n",
    "    except:\n",
    "        return df_preds # Fallback\n",
    "    \n",
    "    Y_reconciled = (P @ Y).T\n",
    "    Y_reconciled = Y_reconciled.clip(min=0) # Non-negative constraint\n",
    "    \n",
    "    df_out = df_preds.copy()\n",
    "    df_out[ordered_cols] = Y_reconciled\n",
    "    return df_out\n",
    "\n",
    "print(\"Loading Data...\")\n",
    "# Load Train (Metadata Split)\n",
    "train_df = pd.read_csv(cfg.SPLIT_PATH) \n",
    "\n",
    "# --- FIX: Remove pre-existing embedding columns to prevent duplication ---\n",
    "cols_to_keep = [c for c in train_df.columns if not c.startswith('emb')]\n",
    "train_df = train_df[cols_to_keep]\n",
    "# -----------------------------------------------------------------------\n",
    "\n",
    "# Ensure train paths match local environment\n",
    "if not str(train_df['image_path'].iloc[0]).startswith('/'):\n",
    "     train_df['image_path'] = train_df['image_path'].apply(lambda p: str(cfg.DATA_PATH / 'train' / os.path.basename(p)))\n",
    "\n",
    "# Load Test\n",
    "test_df_raw = pd.read_csv(cfg.DATA_PATH / 'test.csv')\n",
    "test_df = pivot_table(test_df_raw)\n",
    "test_df['image_path'] = test_df['image_path'].apply(lambda p: str(cfg.DATA_PATH / p))\n",
    "\n",
    "# =========================================================================================\n",
    "# 3. FEATURE EXTRACTION: SIGLIP IMAGE EMBEDDINGS\n",
    "# =========================================================================================\n",
    "def split_image(image, patch_size=520, overlap=16):\n",
    "    h, w, c = image.shape\n",
    "    stride = patch_size - overlap\n",
    "    patches = []\n",
    "    for y in range(0, h, stride):\n",
    "        for x in range(0, w, stride):\n",
    "            y2 = min(y + patch_size, h)\n",
    "            x2 = min(x + patch_size, w)\n",
    "            y1 = max(0, y2 - patch_size) # Ensure fixed size\n",
    "            x1 = max(0, x2 - patch_size)\n",
    "            patch = image[y1:y2, x1:x2, :]\n",
    "            patches.append(patch)\n",
    "    return patches\n",
    "\n",
    "def compute_embeddings(model_path, df):\n",
    "    print(f\"Computing Embeddings for {len(df)} images...\")\n",
    "    model = AutoModel.from_pretrained(model_path, local_files_only=True).eval().to(cfg.DEVICE)\n",
    "    processor = AutoImageProcessor.from_pretrained(model_path)\n",
    "    \n",
    "    EMBEDDINGS = []\n",
    "    \n",
    "    for _, row in tqdm(df.iterrows(), total=len(df)):\n",
    "        try:\n",
    "            img = cv2.imread(row['image_path'])\n",
    "            if img is None: raise ValueError(\"Image not found\")\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            patches = split_image(img, patch_size=cfg.PATCH_SIZE, overlap=cfg.OVERLAP)\n",
    "            images = [Image.fromarray(p) for p in patches]\n",
    "            \n",
    "            # Batch process patches\n",
    "            inputs = processor(images=images, return_tensors=\"pt\").to(cfg.DEVICE)\n",
    "            with torch.no_grad():\n",
    "                features = model.get_image_features(**inputs)\n",
    "            \n",
    "            # Average pooling of patches\n",
    "            avg_embed = features.mean(dim=0).cpu().numpy()\n",
    "            EMBEDDINGS.append(avg_embed)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {row['image_path']}: {e}\")\n",
    "            # Fallback zero embedding\n",
    "            EMBEDDINGS.append(np.zeros(1152))\n",
    "        \n",
    "    torch.cuda.empty_cache()\n",
    "    return np.stack(EMBEDDINGS)\n",
    "\n",
    "# Compute Features\n",
    "train_embeddings = compute_embeddings(cfg.SIGLIP_PATH, train_df)\n",
    "test_embeddings = compute_embeddings(cfg.SIGLIP_PATH, test_df)\n",
    "\n",
    "# Create Feature DataFrames\n",
    "emb_cols = [f\"emb{i}\" for i in range(train_embeddings.shape[1])]\n",
    "train_feat_df = pd.concat([train_df, pd.DataFrame(train_embeddings, columns=emb_cols)], axis=1)\n",
    "test_feat_df = pd.concat([test_df, pd.DataFrame(test_embeddings, columns=emb_cols)], axis=1)\n",
    "\n",
    "# Double check column counts\n",
    "print(f\"Train Features Shape: {train_feat_df.shape}\")\n",
    "print(f\"Test Features Shape: {test_feat_df.shape}\")\n",
    "\n",
    "# =========================================================================================\n",
    "# 4. FEATURE EXTRACTION: SEMANTIC FEATURES (TEXT PROBING)\n",
    "# =========================================================================================\n",
    "def generate_semantic_features(image_embeddings_np, model_path):\n",
    "    print(\"Generating Semantic Features...\")\n",
    "    model = AutoModel.from_pretrained(model_path).to(cfg.DEVICE)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "    \n",
    "    # Anchors\n",
    "    concept_groups = {\n",
    "        \"bare\": [\"bare soil\", \"dirt ground\", \"sparse vegetation\", \"exposed earth\"],\n",
    "        \"sparse\": [\"low density pasture\", \"thin grass\", \"short clipped grass\"],\n",
    "        \"medium\": [\"average pasture cover\", \"medium height grass\", \"grazed pasture\"],\n",
    "        \"dense\": [\"dense tall pasture\", \"thick grassy volume\", \"high biomass\", \"overgrown vegetation\"],\n",
    "        \"green\": [\"lush green vibrant pasture\", \"photosynthesizing leaves\", \"fresh growth\"],\n",
    "        \"dead\": [\"dry brown dead grass\", \"yellow straw\", \"senesced material\", \"standing hay\"],\n",
    "        \"clover\": [\"white clover\", \"trifolium repens\", \"broadleaf legume\", \"clover flowers\"],\n",
    "        \"grass\": [\"ryegrass\", \"blade-like leaves\", \"fescue\", \"grassy sward\"]\n",
    "    }\n",
    "    \n",
    "    # Encode Concepts\n",
    "    concept_vectors = {}\n",
    "    with torch.no_grad():\n",
    "        for name, prompts in concept_groups.items():\n",
    "            inputs = tokenizer(prompts, padding=\"max_length\", return_tensors=\"pt\").to(cfg.DEVICE)\n",
    "            emb = model.get_text_features(**inputs)\n",
    "            emb = emb / emb.norm(p=2, dim=-1, keepdim=True)\n",
    "            concept_vectors[name] = emb.mean(dim=0, keepdim=True)\n",
    "            \n",
    "    # Compute Scores\n",
    "    img_tensor = torch.tensor(image_embeddings_np, dtype=torch.float32).to(cfg.DEVICE)\n",
    "    img_tensor = img_tensor / img_tensor.norm(p=2, dim=-1, keepdim=True)\n",
    "    \n",
    "    scores = {}\n",
    "    for name, vec in concept_vectors.items():\n",
    "        scores[name] = torch.matmul(img_tensor, vec.T).cpu().numpy().flatten()\n",
    "        \n",
    "    df_scores = pd.DataFrame(scores)\n",
    "    # Ratios\n",
    "    df_scores['ratio_greenness'] = df_scores['green'] / (df_scores['green'] + df_scores['dead'] + 1e-6)\n",
    "    df_scores['ratio_clover'] = df_scores['clover'] / (df_scores['clover'] + df_scores['grass'] + 1e-6)\n",
    "    df_scores['ratio_cover'] = (df_scores['dense'] + df_scores['medium']) / (df_scores['bare'] + df_scores['sparse'] + 1e-6)\n",
    "    \n",
    "    torch.cuda.empty_cache()\n",
    "    return df_scores.values\n",
    "\n",
    "# Combine for semantic generation to ensure consistency\n",
    "all_emb = np.vstack([train_embeddings, test_embeddings])\n",
    "all_semantic = generate_semantic_features(all_emb, cfg.SIGLIP_PATH)\n",
    "\n",
    "sem_train = all_semantic[:len(train_df)]\n",
    "sem_test = all_semantic[len(train_df):]\n",
    "\n",
    "# =========================================================================================\n",
    "# 5. SUPERVISED EMBEDDING ENGINE\n",
    "# =========================================================================================\n",
    "class SupervisedEmbeddingEngine:\n",
    "    def __init__(self, n_pca=0.80, n_pls=8, n_gmm=6, random_state=42):\n",
    "        self.scaler = StandardScaler()\n",
    "        self.pca = PCA(n_components=n_pca, random_state=random_state)\n",
    "        self.pls = PLSRegression(n_components=n_pls, scale=False)\n",
    "        self.gmm = GaussianMixture(n_components=n_gmm, covariance_type='diag', random_state=random_state)\n",
    "        self.pls_fitted_ = False\n",
    "\n",
    "    def fit(self, X, y=None, X_semantic=None):\n",
    "        # Scale\n",
    "        X_scaled = self.scaler.fit_transform(X)\n",
    "        \n",
    "        # Unsupervised\n",
    "        self.pca.fit(X_scaled)\n",
    "        self.gmm.fit(X_scaled)\n",
    "        \n",
    "        # Supervised\n",
    "        if y is not None:\n",
    "            self.pls.fit(X_scaled, y)\n",
    "            self.pls_fitted_ = True\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, X_semantic=None):\n",
    "        X_scaled = self.scaler.transform(X)\n",
    "        \n",
    "        features = [self.pca.transform(X_scaled)]\n",
    "        \n",
    "        if self.pls_fitted_:\n",
    "            features.append(self.pls.transform(X_scaled))\n",
    "            \n",
    "        features.append(self.gmm.predict_proba(X_scaled))\n",
    "        \n",
    "        if X_semantic is not None:\n",
    "            # Normalize semantic\n",
    "            sem_norm = (X_semantic - np.mean(X_semantic, axis=0)) / (np.std(X_semantic, axis=0) + 1e-6)\n",
    "            features.append(sem_norm)\n",
    "            \n",
    "        return np.hstack(features)\n",
    "\n",
    "# =========================================================================================\n",
    "# 6. TRAINING & INFERENCE (5-FOLD CV)\n",
    "# =========================================================================================\n",
    "def cross_validate_predict(model_cls, model_params, train_data, test_data, sem_tr, sem_te, feature_engine):\n",
    "    target_max_arr = np.array([cfg.TARGET_MAX[t] for t in cfg.TARGET_NAMES], dtype=float)\n",
    "    y_pred_test_accum = np.zeros([len(test_data), len(cfg.TARGET_NAMES)], dtype=float)\n",
    "    \n",
    "    # Ensure n_splits is integer\n",
    "    n_splits = int(train_data['fold'].nunique())\n",
    "    \n",
    "    # Pre-extract raw columns to avoid indexing overhead\n",
    "    # Force float32 to save memory and ensure compatibility\n",
    "    X_train_full = train_data[emb_cols].values.astype(np.float32)\n",
    "    X_test_raw = test_data[emb_cols].values.astype(np.float32)\n",
    "    y_train_full = train_data[cfg.TARGET_NAMES].values.astype(np.float32)\n",
    "    \n",
    "    for fold in range(n_splits):\n",
    "        print(f\"Processing Fold {fold}...\")\n",
    "        # Split\n",
    "        train_mask = train_data['fold'] != fold\n",
    "        \n",
    "        X_tr = X_train_full[train_mask]\n",
    "        y_tr = y_train_full[train_mask] / target_max_arr # Max Scaling\n",
    "        \n",
    "        sem_tr_fold = sem_tr[train_mask]\n",
    "        \n",
    "        # Feature Engineering (Fit on fold train)\n",
    "        engine = deepcopy(feature_engine)\n",
    "        engine.fit(X_tr, y=y_tr, X_semantic=sem_tr_fold)\n",
    "        \n",
    "        x_tr_eng = engine.transform(X_tr, X_semantic=sem_tr_fold)\n",
    "        x_te_eng = engine.transform(X_test_raw, X_semantic=sem_te)\n",
    "        \n",
    "        # Train & Predict per target\n",
    "        fold_test_pred = np.zeros([len(test_data), len(cfg.TARGET_NAMES)])\n",
    "        \n",
    "        for k in range(len(cfg.TARGET_NAMES)):\n",
    "            model = model_cls(**model_params)\n",
    "            model.fit(x_tr_eng, y_tr[:, k])\n",
    "            pred_raw = model.predict(x_te_eng)\n",
    "            fold_test_pred[:, k] = pred_raw * target_max_arr[k] # Inverse Scale\n",
    "            \n",
    "        y_pred_test_accum += fold_test_pred\n",
    "        \n",
    "    return y_pred_test_accum / n_splits\n",
    "\n",
    "# Model Parameters (Optimized)\n",
    "params_cat = {\n",
    "    'iterations': 1900, 'learning_rate': 0.045, 'depth': 4, 'l2_leaf_reg': 0.56, \n",
    "    'random_strength': 0.045, 'bagging_temperature': 0.98, 'verbose': 0, 'random_state': 42,\n",
    "    'allow_writing_files': False\n",
    "}\n",
    "params_xgb = { # Using GradientBoostingRegressor as proxy\n",
    "    'n_estimators': 1354, 'learning_rate': 0.010, 'max_depth': 3, 'subsample': 0.60, \n",
    "    'random_state': 42\n",
    "}\n",
    "params_lgbm = {\n",
    "    'n_estimators': 807, 'learning_rate': 0.014, 'num_leaves': 48, 'min_child_samples': 19, \n",
    "    'subsample': 0.745, 'colsample_bytree': 0.745, 'reg_alpha': 0.21, 'reg_lambda': 3.78,\n",
    "    'verbose': -1, 'random_state': 42\n",
    "}\n",
    "params_hist = {\n",
    "    'max_iter': 300, 'learning_rate': 0.05, 'max_depth': None, 'l2_regularization': 0.44,\n",
    "    'random_state': 42\n",
    "}\n",
    "\n",
    "feat_engine = SupervisedEmbeddingEngine(n_pca=0.80, n_pls=8, n_gmm=6)\n",
    "\n",
    "print(\"Training & Inferring Models...\")\n",
    "\n",
    "# 1. HistGradientBoosting\n",
    "print(\"Model: HistGradientBoosting\")\n",
    "pred_hist = cross_validate_predict(\n",
    "    HistGradientBoostingRegressor, params_hist, \n",
    "    train_feat_df, test_feat_df, sem_train, sem_test, feat_engine\n",
    ")\n",
    "\n",
    "# 2. GradientBoosting\n",
    "print(\"Model: GradientBoosting\")\n",
    "pred_gb = cross_validate_predict(\n",
    "    GradientBoostingRegressor, params_xgb, \n",
    "    train_feat_df, test_feat_df, sem_train, sem_test, feat_engine\n",
    ")\n",
    "\n",
    "# 3. CatBoost\n",
    "print(\"Model: CatBoost\")\n",
    "pred_cat = cross_validate_predict(\n",
    "    CatBoostRegressor, params_cat, \n",
    "    train_feat_df, test_feat_df, sem_train, sem_test, feat_engine\n",
    ")\n",
    "\n",
    "# 4. LightGBM\n",
    "print(\"Model: LightGBM\")\n",
    "pred_lgbm = cross_validate_predict(\n",
    "    LGBMRegressor, params_lgbm, \n",
    "    train_feat_df, test_feat_df, sem_train, sem_test, feat_engine\n",
    ")\n",
    "\n",
    "# =========================================================================================\n",
    "# 7. ENSEMBLING & SUBMISSION\n",
    "# =========================================================================================\n",
    "print(\"Ensembling and Post-processing...\")\n",
    "# Simple Average Ensemble\n",
    "final_pred = (pred_hist + pred_gb + pred_cat + pred_lgbm) / 4.0\n",
    "\n",
    "# Assign to dataframe\n",
    "test_feat_df[cfg.TARGET_NAMES] = final_pred\n",
    "\n",
    "# Post-process (Mass Balance)\n",
    "test_processed = post_process_biomass(test_feat_df)\n",
    "\n",
    "# Create Submission File\n",
    "sub_df = melt_table(test_processed)\n",
    "output_path = \"submission_siglip.csv\"\n",
    "sub_df.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"✓ Siglip submission generated: {output_path}\")\n",
    "print(sub_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da0a0898",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T06:46:04.447372Z",
     "iopub.status.busy": "2026-01-15T06:46:04.447137Z",
     "iopub.status.idle": "2026-01-15T06:46:04.454226Z",
     "shell.execute_reply": "2026-01-15T06:46:04.453647Z"
    },
    "papermill": {
     "duration": 0.01261,
     "end_time": "2026-01-15T06:46:04.455576",
     "exception": false,
     "start_time": "2026-01-15T06:46:04.442966",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing csiro_infer.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile csiro_infer.py\n",
    "\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import KFold, GroupKFold, StratifiedGroupKFold\n",
    "from tqdm.auto import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import AdamW\n",
    "from transformers import get_cosine_schedule_with_warmup\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms as T\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "import timm\n",
    "import warnings \n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "tqdm.pandas()\n",
    "\n",
    "class RegressionDataset(Dataset):\n",
    "    def __init__(self, data, transform=None):\n",
    "        self.data = data\n",
    "        self.transform = transform\n",
    "    def __len__(self):\n",
    "        return self.data.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.data.iloc[idx]\n",
    "        image = item.image\n",
    "        targets = [item['Dry_Green_g'], item['Dry_Clover_g'], item['Dry_Dead_g']]\n",
    "        width, height = image.size\n",
    "        mid_point = width // 2\n",
    "        left_image = image.crop((0, 0, mid_point, height))\n",
    "        right_image = image.crop((mid_point, 0, width, height))\n",
    "\n",
    "        if self.transform is not None:\n",
    "            left_image = self.transform(left_image)\n",
    "            right_image = self.transform(right_image)\n",
    "\n",
    "        return left_image, right_image, targets\n",
    "\n",
    "def get_test_dataloaders(data, image_size, batch_size):\n",
    "    res = []\n",
    "    for trans in [None, T.RandomHorizontalFlip(p=1.0), T.RandomVerticalFlip(p=1.0)]:\n",
    "        transform = T.Compose([\n",
    "            T.Resize(image_size),\n",
    "            T.ToTensor(),\n",
    "            T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "        if trans:\n",
    "            transform = T.Compose([\n",
    "                T.Resize(image_size),\n",
    "                trans,\n",
    "                T.ToTensor(),\n",
    "                T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "            ])\n",
    "        dataset = RegressionDataset(data, transform=transform)\n",
    "        res.append(DataLoader(dataset, batch_size=batch_size, shuffle=False, num_workers=4))\n",
    "    return res\n",
    "\n",
    "\n",
    "class FiLM(nn.Module):\n",
    "    def __init__(self, feat_dim):\n",
    "        super().__init__()\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(feat_dim, feat_dim // 2), \n",
    "            nn.ReLU(inplace=True), \n",
    "            nn.Linear(feat_dim // 2, feat_dim * 2)\n",
    "        )\n",
    "\n",
    "    def forward(self, context):\n",
    "        gamma_beta = self.mlp(context)\n",
    "        return torch.chunk(gamma_beta, 2, dim=1)\n",
    "\n",
    "class CSIROModelRegressor(nn.Module):\n",
    "    def __init__(self, model_name, pretrained=True, num_classes=3, dropout=0.0, freeze_backbone=False):\n",
    "        super().__init__()\n",
    "        self.backbone = timm.create_model(model_name, pretrained=pretrained, num_classes=0, global_pool='avg')\n",
    "\n",
    "        self.film = FiLM(self.backbone.num_features)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        def make_head():\n",
    "            return nn.Sequential(\n",
    "                nn.Linear(self.backbone.num_features * 2, 8),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Dropout(dropout),\n",
    "                nn.Linear(8, 1),\n",
    "            )\n",
    "\n",
    "        self.head_green = make_head()\n",
    "        self.head_clover = make_head()\n",
    "        self.head_dead = make_head()\n",
    "\n",
    "        self.softplus = nn.Softplus(beta=1.0)\n",
    "\n",
    "        if freeze_backbone:\n",
    "            for p in self.backbone.parameters():\n",
    "                p.requires_grad = False\n",
    "\n",
    "\n",
    "    def forward(self, left_img, right_img):\n",
    "        left_feat = self.backbone(left_img)\n",
    "        right_feat = self.backbone(right_img)\n",
    "\n",
    "        context = (left_feat + right_feat) / 2\n",
    "        gamma, beta = self.film(context)\n",
    "\n",
    "        left_feat_modulated = left_feat * (1 + gamma) + beta\n",
    "        right_feat_modulated = right_feat * (1 + gamma) + beta\n",
    "\n",
    "        combined = torch.cat([left_feat_modulated, right_feat_modulated], dim=1)\n",
    "\n",
    "        green = self.softplus(self.head_green(combined))   \n",
    "        clover = self.softplus(self.head_clover(combined))\n",
    "        dead = self.softplus(self.head_dead(combined)) \n",
    "\n",
    "        logits = torch.cat([green, clover, dead], dim=1)\n",
    "\n",
    "        return logits\n",
    "\n",
    "def predict(model, dataloader, device):\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    all_outputs = []\n",
    "    with torch.no_grad():\n",
    "        for left_images, right_images, targets in dataloader:\n",
    "            left_images = left_images.to(device)\n",
    "            right_images = right_images.to(device)\n",
    "\n",
    "            outputs = model(left_images, right_images)\n",
    "            all_outputs.append(outputs.detach().cpu())\n",
    "\n",
    "    outputs = torch.cat(all_outputs).numpy()\n",
    "    return outputs\n",
    "\n",
    "def predict_loaders(model, dataloaders, device):\n",
    "    all_outputs = []\n",
    "    for dataloader in dataloaders:\n",
    "        outputs = predict(model, dataloader, device)\n",
    "        all_outputs.append(outputs)\n",
    "    avg_outputs = np.mean(all_outputs, axis=0)\n",
    "    return avg_outputs\n",
    "\n",
    "def predict_folds(dataloaders,models_dir):\n",
    "    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    all_preds = []\n",
    "    for model_file in Path(models_dir).glob('*.pth'):\n",
    "        model = CSIROModelRegressor(CFG.MODEL_NAME, pretrained=False, num_classes=3)\n",
    "        model.load_state_dict(torch.load(model_file))\n",
    "        preds = predict_loaders(model, dataloaders, device)\n",
    "        all_preds.append(preds)\n",
    "\n",
    "    avg_preds = np.mean(all_preds, axis=0)\n",
    "    return avg_preds\n",
    "\n",
    "\n",
    "class CFG:\n",
    "    DATA_PATH=\"/kaggle/input/csiro-biomass/\"\n",
    "    TEST_DATA_PATH=\"/kaggle/input/csiro-biomass/test.csv\"\n",
    "    MODEL_NAME=\"vit_large_patch16_dinov3_qkvb\"\n",
    "    MODELS_DIR ='/kaggle/input/csiro-vit-large-dinov3/pytorch/default/1/csiro-dinov3-models'\n",
    "    IMG_SIZE=(512,512)\n",
    "\n",
    "\n",
    "test_df = pd.read_csv(CFG.TEST_DATA_PATH)\n",
    "\n",
    "test_df['target'] = 0.0\n",
    "test_df[['sample_id_prefix', 'sample_id_suffix']] = test_df.sample_id.str.split('__', expand=True)\n",
    "\n",
    "test_data_df = test_df.groupby(['sample_id_prefix', 'image_path']).apply(lambda df: df.set_index('target_name').target)\n",
    "test_data_df.reset_index(inplace=True)\n",
    "test_data_df.columns.name = None\n",
    "\n",
    "test_data_df['image'] = test_data_df.image_path.progress_apply(lambda path: Image.open(CFG.DATA_PATH + path).convert('RGB'))\n",
    "\n",
    "test_loaders = get_test_dataloaders(test_data_df, CFG.IMG_SIZE, 32)\n",
    "preds = predict_folds(test_loaders,models_dir=CFG.MODELS_DIR)\n",
    "\n",
    "test_data_df[['Dry_Green_g', 'Dry_Clover_g', 'Dry_Dead_g']] = preds\n",
    "test_data_df['GDM_g'] = test_data_df.Dry_Green_g + test_data_df.Dry_Clover_g\n",
    "test_data_df['Dry_Total_g'] = test_data_df.GDM_g + test_data_df.Dry_Dead_g\n",
    "\n",
    "cols = [ 'Dry_Green_g', 'Dry_Dead_g', 'Dry_Clover_g', 'GDM_g' , 'Dry_Total_g']\n",
    "sub_df = test_data_df.set_index('sample_id_prefix')[cols].stack()\n",
    "sub_df = sub_df.reset_index()\n",
    "sub_df.columns = ['sample_id_prefix', 'target_name', 'target']\n",
    "\n",
    "sub_df['sample_id'] = sub_df.sample_id_prefix + '__' + sub_df.target_name\n",
    "\n",
    "cols = ['sample_id', 'target']\n",
    "sub_df[cols].to_csv('submission_dinov2026.csv', index=False)\n",
    "\n",
    "print(sub_df[cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "48889e64",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T06:46:04.462169Z",
     "iopub.status.busy": "2026-01-15T06:46:04.461921Z",
     "iopub.status.idle": "2026-01-15T06:47:33.988995Z",
     "shell.execute_reply": "2026-01-15T06:47:33.987964Z"
    },
    "papermill": {
     "duration": 89.532853,
     "end_time": "2026-01-15T06:47:33.991217",
     "exception": false,
     "start_time": "2026-01-15T06:46:04.458364",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\r\n",
      "  warnings.warn(\r\n",
      "/usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\r\n",
      "  warnings.warn(\r\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00, 11.19it/s]\r\n",
      "                    sample_id     target\r\n",
      "0   ID1001187975__Dry_Green_g  28.325821\r\n",
      "1    ID1001187975__Dry_Dead_g  34.191360\r\n",
      "2  ID1001187975__Dry_Clover_g   0.020916\r\n",
      "3         ID1001187975__GDM_g  28.346737\r\n",
      "4   ID1001187975__Dry_Total_g  62.538097\r\n"
     ]
    }
   ],
   "source": [
    "!python csiro_infer.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b7e25ee5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T06:47:33.999523Z",
     "iopub.status.busy": "2026-01-15T06:47:33.999240Z",
     "iopub.status.idle": "2026-01-15T06:47:34.032128Z",
     "shell.execute_reply": "2026-01-15T06:47:34.031298Z"
    },
    "papermill": {
     "duration": 0.039068,
     "end_time": "2026-01-15T06:47:34.033535",
     "exception": false,
     "start_time": "2026-01-15T06:47:33.994467",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting Ensemble ---\n",
      "Weights: {'siglip': 0.35, 'dino': 0.65}\n",
      "Loaded siglip: 5 rows\n",
      "Loaded dino: 5 rows\n",
      "Weighted average complete.\n",
      "Applying Mass Balance Constraints...\n",
      "\n",
      "Success! Saved to submission.csv\n",
      "                    sample_id     target\n",
      "0  ID1001187975__Dry_Clover_g   1.319347\n",
      "1    ID1001187975__Dry_Dead_g  29.743026\n",
      "2   ID1001187975__Dry_Green_g  28.404697\n",
      "3   ID1001187975__Dry_Total_g  59.467070\n",
      "4         ID1001187975__GDM_g  29.724044\n",
      "\n",
      "Stats:\n",
      "count     5.000000\n",
      "mean     29.731637\n",
      "std      20.574348\n",
      "min       1.319347\n",
      "25%      28.404697\n",
      "50%      29.724044\n",
      "75%      29.743026\n",
      "max      59.467070\n",
      "Name: target, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# =============================================================================\n",
    "# CONFIGURATION\n",
    "# =============================================================================\n",
    "# Weights for the ensemble (Must sum to 1.0)\n",
    "# Adjust based on which model had better local CV or Public LB score.\n",
    "# Example: If Siglip was better, give it 0.6.\n",
    "W_SIGLIP = 0.35\n",
    "W_DINO   = 0.65\n",
    "\n",
    "FILES = {\n",
    "    'siglip': 'submission_siglip.csv',\n",
    "    'dino':   'submission_dinov2026.csv'\n",
    "}\n",
    "\n",
    "OUTPUT_FILE = 'submission.csv'\n",
    "\n",
    "# Target definitions required for Mass Balance\n",
    "ALL_TARGETS = ['Dry_Green_g', 'Dry_Clover_g', 'Dry_Dead_g', 'GDM_g', 'Dry_Total_g']\n",
    "\n",
    "# =============================================================================\n",
    "# HELPER FUNCTIONS\n",
    "# =============================================================================\n",
    "\n",
    "def enforce_mass_balance(df_wide):\n",
    "    \"\"\"\n",
    "    Applies Orthogonal Projection to enforce biological constraints:\n",
    "    1. Dry_Green_g + Dry_Clover_g = GDM_g\n",
    "    2. GDM_g + Dry_Dead_g = Dry_Total_g\n",
    "    \n",
    "    This finds the closest set of values to the predictions that satisfy \n",
    "    the constraints (minimizing Euclidean distance modification).\n",
    "    \"\"\"\n",
    "    # 1. Ensure columns are in the specific order for the matrix math\n",
    "    # Vector x = [Green, Clover, Dead, GDM, Total]\n",
    "    ordered_cols = ['Dry_Green_g', 'Dry_Clover_g', 'Dry_Dead_g', 'GDM_g', 'Dry_Total_g']\n",
    "    \n",
    "    # Extract values: Shape (5, N_samples)\n",
    "    Y = df_wide[ordered_cols].values.T\n",
    "    \n",
    "    # 2. Define Constraint Matrix C where Cx = 0\n",
    "    # Eq 1: 1*Gr + 1*Cl + 0*De - 1*GDM + 0*Tot = 0\n",
    "    # Eq 2: 0*Gr + 0*Cl + 1*De + 1*GDM - 1*Tot = 0\n",
    "    C = np.array([\n",
    "        [1, 1, 0, -1,  0],\n",
    "        [0, 0, 1,  1, -1]\n",
    "    ])\n",
    "    \n",
    "    # 3. Calculate Projection Matrix P = I - C^T * (C * C^T)^-1 * C\n",
    "    C_T = C.T\n",
    "    try:\n",
    "        inv_CCt = np.linalg.inv(C @ C_T)\n",
    "        P = np.eye(5) - C_T @ inv_CCt @ C\n",
    "    except np.linalg.LinAlgError:\n",
    "        # Fallback if singular (unlikely with this specific matrix)\n",
    "        print(\"Warning: Singular matrix in projection. Skipping constraint enforcement.\")\n",
    "        return df_wide\n",
    "\n",
    "    # 4. Apply Projection\n",
    "    Y_reconciled = P @ Y\n",
    "    \n",
    "    # 5. Transpose back to (N_samples, 5) and clip negatives\n",
    "    Y_reconciled = Y_reconciled.T\n",
    "    Y_reconciled = np.maximum(0, Y_reconciled) \n",
    "    \n",
    "    # 6. Update DataFrame\n",
    "    df_out = df_wide.copy()\n",
    "    df_out[ordered_cols] = Y_reconciled\n",
    "    \n",
    "    return df_out\n",
    "\n",
    "def robust_ensemble(file_paths, weights):\n",
    "    print(f\"--- Starting Ensemble ---\")\n",
    "    print(f\"Weights: {weights}\")\n",
    "    \n",
    "    dfs = []\n",
    "    for name, path in file_paths.items():\n",
    "        if not os.path.exists(path):\n",
    "            raise FileNotFoundError(f\"Missing file: {path}\")\n",
    "        \n",
    "        # Read and sort by sample_id to ensure alignment\n",
    "        df = pd.read_csv(path).sort_values('sample_id').reset_index(drop=True)\n",
    "        dfs.append(df)\n",
    "        print(f\"Loaded {name}: {len(df)} rows\")\n",
    "\n",
    "    # 1. Check alignment\n",
    "    base_ids = dfs[0]['sample_id']\n",
    "    if not all(df['sample_id'].equals(base_ids) for df in dfs[1:]):\n",
    "        raise ValueError(\"Sample IDs do not match between submission files!\")\n",
    "\n",
    "    # 2. Weighted Average\n",
    "    # Stack targets: (N_samples, N_models)\n",
    "    all_preds = np.column_stack([df['target'].values for df in dfs])\n",
    "    w_vec = np.array(list(weights.values()))\n",
    "    \n",
    "    # Normalize weights just in case\n",
    "    w_vec = w_vec / w_vec.sum()\n",
    "    \n",
    "    # Compute average\n",
    "    avg_preds = np.sum(all_preds * w_vec, axis=1)\n",
    "    \n",
    "    # Create intermediate dataframe\n",
    "    ensemble_df = pd.DataFrame({\n",
    "        'sample_id': base_ids,\n",
    "        'target': avg_preds\n",
    "    })\n",
    "    \n",
    "    print(\"Weighted average complete.\")\n",
    "\n",
    "    # 3. Prepare for Mass Balance (Convert Long -> Wide)\n",
    "    # Split sample_id into image_id and target_name\n",
    "    # Format: ID1001187975__Dry_Green_g\n",
    "    ensemble_df[['image_id', 'target_name']] = ensemble_df['sample_id'].str.rsplit('__', n=1, expand=True)\n",
    "    \n",
    "    # Pivot\n",
    "    wide_df = ensemble_df.pivot(index='image_id', columns='target_name', values='target').reset_index()\n",
    "    \n",
    "    # 4. Apply Robust Constraints\n",
    "    print(\"Applying Mass Balance Constraints...\")\n",
    "    wide_balanced = enforce_mass_balance(wide_df)\n",
    "    \n",
    "    # 5. Convert back (Wide -> Long)\n",
    "    long_balanced = wide_balanced.melt(\n",
    "        id_vars='image_id', \n",
    "        value_vars=ALL_TARGETS,\n",
    "        var_name='target_name',\n",
    "        value_name='target'\n",
    "    )\n",
    "    \n",
    "    # Reconstruct sample_id\n",
    "    long_balanced['sample_id'] = long_balanced['image_id'] + '__' + long_balanced['target_name']\n",
    "    \n",
    "    # 6. Final Formatting\n",
    "    final_submission = long_balanced[['sample_id', 'target']].sort_values('sample_id').reset_index(drop=True)\n",
    "    \n",
    "    return final_submission\n",
    "\n",
    "# =============================================================================\n",
    "# EXECUTION\n",
    "# =============================================================================\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    # Define weights\n",
    "    ensemble_weights = {\n",
    "        'siglip': W_SIGLIP,\n",
    "        'dino': W_DINO\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        # Run Ensemble\n",
    "        submission = robust_ensemble(FILES, ensemble_weights)\n",
    "        \n",
    "        # Save\n",
    "        submission.to_csv(OUTPUT_FILE, index=False)\n",
    "        print(f\"\\nSuccess! Saved to {OUTPUT_FILE}\")\n",
    "        print(submission.head())\n",
    "        \n",
    "        # Sanity Check Stats\n",
    "        print(\"\\nStats:\")\n",
    "        print(submission['target'].describe())\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\nError during ensembling: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 14254895,
     "sourceId": 112509,
     "sourceType": "competition"
    },
    {
     "datasetId": 9262645,
     "sourceId": 14502460,
     "sourceType": "datasetVersion"
    },
    {
     "sourceId": 288467413,
     "sourceType": "kernelVersion"
    },
    {
     "modelId": 553604,
     "modelInstanceId": 540408,
     "sourceId": 711299,
     "sourceType": "modelInstanceVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 251887,
     "modelInstanceId": 230141,
     "sourceId": 268942,
     "sourceType": "modelInstanceVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 557864,
     "modelInstanceId": 544792,
     "sourceId": 716648,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 31236,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1120.485872,
   "end_time": "2026-01-15T06:47:37.613412",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2026-01-15T06:28:57.127540",
   "version": "2.6.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "077c80aa5f454b79b9300e6b708ab12a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_b32cad631cd64fe0b86b2770277c60f2",
       "max": 1,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_d8ed877c676540b79345dc39b61edf75",
       "tabbable": null,
       "tooltip": null,
       "value": 1
      }
     },
     "16e88e4e43b942d69b187ad7dfbd6c02": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "17ef7b08be804fa58e59a6663e63da11": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "1e6205d66ca64fecaa9d806d8abc2f90": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_d4bdd9a4256d480d8a333c7668816c95",
        "IPY_MODEL_077c80aa5f454b79b9300e6b708ab12a",
        "IPY_MODEL_d8f74ddc6fc14c33b62765ce43177c34"
       ],
       "layout": "IPY_MODEL_71940bf102d9496498dace4742483538",
       "tabbable": null,
       "tooltip": null
      }
     },
     "223fdc37afcc4e94aaea9254ad714305": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_3f2e78bb59184d9ba7dc98d76f3020e3",
       "placeholder": "​",
       "style": "IPY_MODEL_dd23a0eca5a24c42b4a2df3f69f48715",
       "tabbable": null,
       "tooltip": null,
       "value": "100%"
      }
     },
     "397f7201c80541a2a83c6d977038e847": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "3f2e78bb59184d9ba7dc98d76f3020e3": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "4481a78cf7834310b889b0fae215ee07": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_701192c871eb4f1785d48b94e5dd22fa",
       "max": 357,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_397f7201c80541a2a83c6d977038e847",
       "tabbable": null,
       "tooltip": null,
       "value": 357
      }
     },
     "701192c871eb4f1785d48b94e5dd22fa": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "71940bf102d9496498dace4742483538": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "8276747aaed841548cc74d48b646de0d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "8bfecf6081384a6cab38b950e541c9e2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_adbf368693a342b18af54e03be50b158",
       "placeholder": "​",
       "style": "IPY_MODEL_8276747aaed841548cc74d48b646de0d",
       "tabbable": null,
       "tooltip": null,
       "value": " 357/357 [12:25&lt;00:00,  2.14s/it]"
      }
     },
     "9b1b7162c07c412693d9292e1d086060": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_223fdc37afcc4e94aaea9254ad714305",
        "IPY_MODEL_4481a78cf7834310b889b0fae215ee07",
        "IPY_MODEL_8bfecf6081384a6cab38b950e541c9e2"
       ],
       "layout": "IPY_MODEL_17ef7b08be804fa58e59a6663e63da11",
       "tabbable": null,
       "tooltip": null
      }
     },
     "9bf96e98e50f4575afdecb96ac6926b2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "9eac23cd3bed4a7b9f832d7190cb47c7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "adbf368693a342b18af54e03be50b158": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "b32cad631cd64fe0b86b2770277c60f2": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "d4bdd9a4256d480d8a333c7668816c95": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_eac0ad6a95c747c2a32b2b476d5b20ea",
       "placeholder": "​",
       "style": "IPY_MODEL_9eac23cd3bed4a7b9f832d7190cb47c7",
       "tabbable": null,
       "tooltip": null,
       "value": "100%"
      }
     },
     "d8ed877c676540b79345dc39b61edf75": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "d8f74ddc6fc14c33b62765ce43177c34": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_16e88e4e43b942d69b187ad7dfbd6c02",
       "placeholder": "​",
       "style": "IPY_MODEL_9bf96e98e50f4575afdecb96ac6926b2",
       "tabbable": null,
       "tooltip": null,
       "value": " 1/1 [00:02&lt;00:00,  2.15s/it]"
      }
     },
     "dd23a0eca5a24c42b4a2df3f69f48715": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "eac0ad6a95c747c2a32b2b476d5b20ea": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
